#!/usr/bin/env python3

"""Main application module.

Builds the Paper Podcast Generator application using Gradio.
"""
import math
import os
import time
from pathlib import Path
from typing import Any, Dict, List, Optional

import gradio as gr

from yomitalk.common.character import DISPLAY_NAMES
from yomitalk.components.audio_generator import AudioGenerator
from yomitalk.components.content_extractor import ContentExtractor
from yomitalk.components.text_processor import TextProcessor
from yomitalk.prompt_manager import DocumentType, PodcastMode
from yomitalk.utils.logger import logger
from yomitalk.utils.session_manager import SessionManager

# Check for base directories
os.makedirs("data/temp", exist_ok=True)
os.makedirs("data/output", exist_ok=True)

# E2E test mode for faster startup
E2E_TEST_MODE = os.environ.get("E2E_TEST_MODE", "false").lower() == "true"

# Default port
DEFAULT_PORT = 7860


# Application class
class PaperPodcastApp:
    """Main class for the Paper Podcast Generator application."""

    def __init__(self):
        """Initialize the PaperPodcastApp.

        Creates instances of FileUploader, TextProcessor, and AudioGenerator.
        """
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã®åˆæœŸåŒ–
        self.session_manager = SessionManager()
        logger.info(
            f"Initializing app with session ID: {self.session_manager.get_session_id()}"
        )

        self.content_extractor = ContentExtractor()
        self.text_processor = TextProcessor()
        self.audio_generator = AudioGenerator(
            session_output_dir=self.session_manager.get_output_dir(),
            session_temp_dir=self.session_manager.get_talk_temp_dir(),
        )

        # ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹LLMã‚¿ã‚¤ãƒ—
        self.current_llm_type = "gemini"

        # TextProcessorã®APIç¨®åˆ¥ã‚‚åˆæœŸè¨­å®š
        self.text_processor.set_api_type("gemini")

    @property
    def current_podcast_mode(self) -> PodcastMode:
        """ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        return self.text_processor.get_podcast_mode()

    @property
    def current_document_type(self) -> DocumentType:
        """ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        return self.text_processor.get_document_type()

    def set_openai_api_key(self, api_key: str):
        """
        Set the OpenAI API key and returns a result message based on the outcome.

        Args:
            api_key (str): OpenAI API key
        """
        # APIã‚­ãƒ¼ãŒç©ºç™½ã‚„ç©ºæ–‡å­—ã®å ´åˆã¯å‡¦ç†ã—ãªã„
        if not api_key or api_key.strip() == "":
            logger.warning("OpenAI API key is empty")
            return

        success = self.text_processor.set_openai_api_key(api_key)
        logger.debug(f"OpenAI API key set: {success}")

    def set_gemini_api_key(self, api_key: str):
        """
        Set the Google Gemini API key and returns a result message based on the outcome.

        Args:
            api_key (str): Google API key
        """
        # APIã‚­ãƒ¼ãŒç©ºç™½ã‚„ç©ºæ–‡å­—ã®å ´åˆã¯å‡¦ç†ã—ãªã„
        if not api_key or api_key.strip() == "":
            logger.warning("Gemini API key is empty")
            return

        success = self.text_processor.set_gemini_api_key(api_key)
        logger.debug(f"Gemini API key set: {success}")

    def switch_llm_type(self, llm_type: str) -> None:
        """
        LLMã‚¿ã‚¤ãƒ—ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚

        Args:
            llm_type (str): "openai" ã¾ãŸã¯ "gemini"
        """
        if llm_type not in ["openai", "gemini"]:
            logger.warning(f"Invalid LLM type: {llm_type}")
            return

        success = self.text_processor.set_api_type(llm_type)
        if success:
            self.current_llm_type = llm_type
            api_name = "OpenAI" if llm_type == "openai" else "Google Gemini"
            logger.debug(f"LLM type switched to {api_name}")
        else:
            api_name = "OpenAI" if llm_type == "openai" else "Google Gemini"
            logger.warning(f"{api_name} API key not set")

    def extract_file_text(self, file_obj) -> str:
        """
        Extract text from a file.

        Args:
            file_obj: Uploaded file object

        Returns:
            str: extracted_text
        """
        if file_obj is None:
            logger.warning("No file selected for extraction")
            return "Please upload a file."

        # ãƒ¡ãƒ¢ãƒªä¸Šã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’è¡Œã†
        text = self.content_extractor.extract_text(file_obj)
        logger.debug("Text extraction completed (memory-based)")
        return text

    def generate_podcast_text(self, text: str) -> str:
        """
        Generate podcast-style text from input text.

        Args:
            text (str): Input text from file

        Returns:
            str: generated_podcast_text
        """
        if not text:
            logger.warning("Podcast text generation: Input text is empty")
            return "Please upload a file and extract text first."

        # Check if API key is set
        if (
            self.current_llm_type == "openai"
            and not self.text_processor.openai_model.api_key
        ):
            logger.warning("Podcast text generation: OpenAI API key not set")
            return "OpenAI API key is not set. Please configure it in the Settings tab."
        elif (
            self.current_llm_type == "gemini"
            and not self.text_processor.gemini_model.api_key
        ):
            logger.warning("Podcast text generation: Gemini API key not set")
            return "Google Gemini API key is not set. Please configure it in the Settings tab."

        try:
            # Generate podcast text
            podcast_text = self.text_processor.process_text(text)

            # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨çŠ¶æ³ã‚’å–å¾—ã—ã¦ãƒ­ã‚°ã«è¿½åŠ 
            token_usage = self.text_processor.get_token_usage()
            if token_usage:
                usage_msg = f"Token usage: input {token_usage.get('prompt_tokens', 0)}, output {token_usage.get('completion_tokens', 0)}, total {token_usage.get('total_tokens', 0)}"
                logger.debug(usage_msg)

            logger.debug("Podcast text generation completed")
            return podcast_text
        except Exception as e:
            error_msg = f"Podcast text generation error: {str(e)}"
            logger.error(error_msg)
            return f"Error: {str(e)}"

    def generate_podcast_audio_streaming(self, text: str, progress=gr.Progress()):
        """
        Generate streaming audio from podcast text.
        æœ€çµ‚çš„ãªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç”Ÿæˆã—ã€ã‚¯ãƒ©ã‚¹å¤‰æ•°ã«ä¿æŒã™ã‚‹
        é€²æ—æƒ…å ±ã‚‚ã‚¯ãƒ©ã‚¹å¤‰æ•°ã«ä¿å­˜ã™ã‚‹ï¼ˆé€²æ—è¡¨ç¤ºã¯è¡Œã‚ãªã„ï¼‰

        Args:
            text (str): Generated podcast text
            progress (gr.Progress): Gradio Progress object (not used directly)

        Yields:
            str: Path to audio file chunks for streaming playback
        """
        if not text:
            logger.warning("Streaming audio generation: Text is empty")
            yield None
            return

        # Check if VOICEVOX Core is available
        if not self.audio_generator.core_initialized:
            logger.error("Streaming audio generation: VOICEVOX Core is not available")
            yield None
            return

        try:
            # åˆå›ã®yieldã‚’è¡Œã£ã¦ã€Gradioã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’ç¢ºå®Ÿã«æœ‰åŠ¹åŒ–
            logger.debug("Initializing streaming audio generation")
            yield None

            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ã®å„ãƒ‘ãƒ¼ãƒˆã®ãƒ‘ã‚¹ã‚’ä¿å­˜
            parts_paths = []
            final_combined_path = None

            # å€‹åˆ¥ã®éŸ³å£°ãƒ‘ãƒ¼ãƒˆã‚’ç”Ÿæˆãƒ»ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
            for audio_path in self.audio_generator.generate_character_conversation(
                text
            ):
                if not audio_path:
                    continue

                filename = os.path.basename(audio_path)

                # 'part_'ã‚’å«ã‚€ã‚‚ã®ã¯éƒ¨åˆ†éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã€'audio_'ã‹ã‚‰å§‹ã¾ã‚‹ã‚‚ã®ã¯æœ€çµ‚çµåˆãƒ•ã‚¡ã‚¤ãƒ«
                if "part_" in filename:
                    parts_paths.append(audio_path)
                    logger.debug(f"ã‚¹ãƒˆãƒªãƒ¼ãƒ éŸ³å£°ãƒ‘ãƒ¼ãƒ„ ({len(parts_paths)}): {audio_path}")
                    yield audio_path  # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å†ç”Ÿç”¨ã«yield
                    time.sleep(0.05)  # é€£ç¶šå†ç”Ÿã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°èª¿æ•´
                elif filename.startswith("audio_"):
                    # æœ€çµ‚çµåˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                    final_combined_path = audio_path
                    logger.info(f"çµåˆæ¸ˆã¿æœ€çµ‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å—ä¿¡: {final_combined_path}")

            # éŸ³å£°ç”Ÿæˆã®å®Œäº†å‡¦ç†
            self._finalize_audio_generation(final_combined_path, parts_paths)

        except Exception as e:
            logger.error(f"Streaming audio generation exception: {str(e)}")
            self.audio_generator.audio_generation_progress = 0.0  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯é€²æ—ã‚’ãƒªã‚»ãƒƒãƒˆ
            yield None

    def _finalize_audio_generation(self, final_combined_path, parts_paths):
        """
        éŸ³å£°ç”Ÿæˆã®æœ€çµ‚å‡¦ç†ã‚’è¡Œã†

        Args:
            final_combined_path (str): çµåˆã•ã‚ŒãŸæœ€çµ‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            parts_paths (List[str]): éƒ¨åˆ†éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        """
        # æœ€çµ‚çµåˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ãŒå–å¾—ã§ããŸå ´åˆ
        if final_combined_path and os.path.exists(final_combined_path):
            # é€²æ—ã‚’æ›´æ–°
            self.audio_generator.audio_generation_progress = 0.9
            logger.info(f"æœ€çµ‚çµåˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {final_combined_path}")

            # æœ€çµ‚çš„ãªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ä¿å­˜
            self.audio_generator.final_audio_path = final_combined_path

            # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›¸ãè¾¼ã¿ã‚’ç¢ºå®Ÿã«ã™ã‚‹ãŸã‚å°‘ã—å¾…æ©Ÿ
            time.sleep(0.2)

            if os.path.exists(final_combined_path):
                filesize = os.path.getsize(final_combined_path)
                # é€²æ—ã‚’å®Œäº†çŠ¶æ…‹ã«æ›´æ–°
                self.audio_generator.audio_generation_progress = 1.0
                logger.info(
                    f"éŸ³å£°ç”Ÿæˆå®Œäº†: {final_combined_path} (ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {filesize} bytes)"
                )
            else:
                logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªããªã‚Šã¾ã—ãŸ: {final_combined_path}")
                self._use_fallback_audio(parts_paths)

        # æœ€çµ‚çµåˆãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
        else:
            self._use_fallback_audio(parts_paths)

    def _use_fallback_audio(self, parts_paths):
        """
        çµåˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå–å¾—ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†

        Args:
            parts_paths (List[str]): éƒ¨åˆ†éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        """
        # éƒ¨åˆ†éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯æœ€å¾Œã®ãƒ‘ãƒ¼ãƒˆã‚’ä½¿ç”¨
        if parts_paths:
            logger.warning("çµåˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€æœ€å¾Œã®ãƒ‘ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™")
            self.audio_generator.final_audio_path = parts_paths[-1]
            self.audio_generator.audio_generation_progress = 1.0

            if os.path.exists(parts_paths[-1]):
                filesize = os.path.getsize(parts_paths[-1])
                logger.info(
                    f"éƒ¨åˆ†éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨: {parts_paths[-1]} (ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {filesize} bytes)"
                )
            else:
                logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å­˜åœ¨ã—ã¾ã›ã‚“: {parts_paths[-1]}")
                self.audio_generator.audio_generation_progress = 0.0
        else:
            logger.warning("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            self.audio_generator.audio_generation_progress = 0.0

    def disable_generate_button(self):
        """éŸ³å£°ç”Ÿæˆãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã™ã€‚

        Returns:
            Dict[str, Any]: gr.update()ã®çµæœ
        """
        return gr.update(interactive=False, value="éŸ³å£°ç”Ÿæˆä¸­...")

    def enable_generate_button(self, podcast_text):
        """éŸ³å£°ç”Ÿæˆãƒœã‚¿ãƒ³ã‚’å†ã³æœ‰åŠ¹åŒ–ã—ã¾ã™ã€‚

        Args:
            podcast_text (str): ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯åŸç¨¿ï¼ˆçŠ¶æ…‹ç¢ºèªç”¨ï¼‰

        Returns:
            Dict[str, Any]: gr.update()ã®çµæœ
        """
        has_text = podcast_text and podcast_text.strip() != ""
        return gr.update(
            interactive=True,
            value="éŸ³å£°ã‚’ç”Ÿæˆ",
            variant="primary" if has_text else "secondary",
        )

    def disable_process_button(self):
        """ãƒˆãƒ¼ã‚¯åŸç¨¿ç”Ÿæˆãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã™ã€‚

        Returns:
            Dict[str, Any]: gr.update()ã®çµæœ
        """
        return gr.update(interactive=False, value="ãƒˆãƒ¼ã‚¯åŸç¨¿ç”Ÿæˆä¸­...")

    def enable_process_button(self, extracted_text):
        """ãƒˆãƒ¼ã‚¯åŸç¨¿ç”Ÿæˆãƒœã‚¿ãƒ³ã‚’å†ã³æœ‰åŠ¹åŒ–ã—ã¾ã™ã€‚

        Args:
            extracted_text (str): ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã®å†…å®¹ï¼ˆçŠ¶æ…‹ç¢ºèªç”¨ï¼‰

        Returns:
            Dict[str, Any]: gr.update()ã®çµæœ
        """
        # ç¾åœ¨ã®APIã‚­ãƒ¼ã¨ãƒ†ã‚­ã‚¹ãƒˆã®çŠ¶æ…‹ã«åŸºã¥ã„ã¦ãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã‚’æ›´æ–°
        has_text = (
            extracted_text
            and extracted_text.strip() != ""
            and extracted_text
            not in ["Please upload a file.", "Failed to process the file."]
        )
        has_api_key = False

        if self.current_llm_type == "openai":
            has_api_key = bool(self.text_processor.openai_model.api_key)
        elif self.current_llm_type == "gemini":
            has_api_key = bool(self.text_processor.gemini_model.api_key)

        is_enabled = has_text and has_api_key

        return gr.update(
            interactive=is_enabled,
            value="ãƒˆãƒ¼ã‚¯åŸç¨¿ã‚’ç”Ÿæˆ",
            variant="primary" if is_enabled else "secondary",
        )

    def ui(self) -> gr.Blocks:
        """
        Create the Gradio interface.

        Returns:
            gr.Blocks: Gradio Blocks instance
        """
        app = gr.Blocks(
            title="Yomitalk",
            css="footer {display: none !important;}",
            theme=gr.themes.Soft(),
        )

        # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã§ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
        # Hugging Face Spacesã®ç„¡æ–™CPUã‚’åŠ¹ç‡çš„ã«ä½¿ã†ãŸã‚ã€åŒæ™‚å®Ÿè¡Œæ•°ã‚’1ã«åˆ¶é™
        app.queue(
            default_concurrency_limit=1,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®åŒæ™‚å®Ÿè¡Œæ•°ã‚’1ã«åˆ¶é™
            api_open=False,  # APIã‚¢ã‚¯ã‚»ã‚¹ã‚’åˆ¶é™
            max_size=5,  # ã‚­ãƒ¥ãƒ¼å†…ã®æœ€å¤§ã‚¿ã‚¹ã‚¯æ•°ã‚’åˆ¶é™
            status_update_rate=1,  # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°é »åº¦ï¼ˆç§’ï¼‰
        )

        with app:
            # ãƒ˜ãƒƒãƒ€ãƒ¼éƒ¨åˆ†ã‚’ãƒ­ã‚´ã¨å…è²¬äº‹é …ã‚’å«ã‚€ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã«å¤‰æ›´
            with gr.Row(equal_height=True, variant="panel", elem_classes="header-row"):
                with gr.Column(scale=1, min_width=200, elem_classes="logo-column"):
                    gr.Image(
                        "assets/images/logo.png",
                        show_label=False,
                        show_download_button=False,
                        show_fullscreen_button=False,
                        container=False,
                        scale=1,
                    )
                with gr.Column(scale=3, elem_classes="disclaimer-column"):
                    with gr.Row(elem_id="disclaimer-container"):
                        gr.Markdown(
                            """**ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆé¢¨ã®è§£èª¬éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³**

                            **å…è²¬äº‹é …**: ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯LLMï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ç”Ÿæˆã•ã‚Œã‚‹å†…å®¹ã®æ­£ç¢ºæ€§ã€å®Œå…¨æ€§ã€é©åˆ‡æ€§ã«ã¤ã„ã¦ä¿è¨¼ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚
                            ã¾ãŸã€ç§˜å¯†æ–‡æ›¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¯æ¨å¥¨ã•ã‚Œã¾ã›ã‚“ã€‚å½“ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½¿ç”¨ã«ã‚ˆã‚Šç”Ÿã˜ãŸã€ã„ã‹ãªã‚‹æå®³ã«ã¤ã„ã¦ã‚‚è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚""",
                            elem_id="disclaimer-text",
                        )

            # ã‚«ã‚¹ã‚¿ãƒ CSSã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¿½åŠ 
            css = """
            /* ãƒ­ã‚´ç”»åƒã®ã‚¹ã‚¿ã‚¤ãƒ«èª¿æ•´ */
            .gradio-image {
                margin: 0 !important;
                padding: 0 !important;
                display: flex !important;
                align-items: flex-end !important;
            }

            /* ãƒ­ã‚´ç”»åƒã‚³ãƒ³ãƒ†ãƒŠã®å·¦ä½™ç™½ã‚’å‰Šé™¤ */
            .gradio-column:has(> .gradio-image) {
                padding-left: 0 !important;
            }

            /* ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®ã‚¹ã‚¿ã‚¤ãƒ«èª¿æ•´ */
            .header-row {
                display: flex !important;
                align-items: flex-end !important;
                min-height: 80px !important;
            }

            /* å…è²¬äº‹é …ã®åˆ—ã®ã‚¹ã‚¿ã‚¤ãƒ«èª¿æ•´ */
            .disclaimer-column {
                display: flex !important;
                align-items: flex-end !important;
            }

            /* å…è²¬äº‹é …ã®ã‚³ãƒ³ãƒ†ãƒŠã‚¹ã‚¿ã‚¤ãƒ« */
            #disclaimer-container {
                display: flex !important;
                align-items: flex-end !important;
                height: 100% !important;
                margin-bottom: 0 !important;
                padding: 5px 0 !important;
                width: 100% !important;
            }

            /* å…è²¬äº‹é …ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚¿ã‚¤ãƒ« */
            #disclaimer-text p {
                margin: 0 !important;
                padding-bottom: 5px !important;
                font-size: 0.9em !important;
                line-height: 1.4 !important;
                max-width: 100% !important;
            }

            /* ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå‡ºåŠ›ã®ã‚¹ã‚¿ã‚¤ãƒ«èª¿æ•´ */
            #audio_output {
                min-height: 180px !important;
                margin-bottom: 10px;
            }

            #audio_output.empty::before {
                content: "éŸ³å£°ç”ŸæˆãŒå®Œäº†ã™ã‚‹ã¨ã€ã“ã“ã«æ³¢å½¢ã¨å†ç”Ÿã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãŒè¡¨ç¤ºã•ã‚Œã¾ã™";
                display: flex;
                justify-content: center;
                align-items: center;
                height: 140px;
                color: #555;
                font-style: italic;
                background-color: rgba(0,0,0,0.03);
                border-radius: 8px;
                text-align: center;
                padding: 10px;
            }

            #streaming_audio_output.empty::before {
                content: "éŸ³å£°ç”ŸæˆãŒé–‹å§‹ã•ã‚Œã‚‹ã¨ã€ã“ã“ã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å†ç”Ÿã§ãã¾ã™";
                display: flex;
                justify-content: center;
                align-items: center;
                height: 80px;
                color: #555;
                font-style: italic;
                background-color: rgba(0,0,0,0.03);
                border-radius: 8px;
                text-align: center;
                padding: 10px;
            }
            """
            gr.HTML(f"<style>{css}</style>")

            with gr.Column():
                gr.Markdown("""## ãƒˆãƒ¼ã‚¯åŸç¨¿ã®ç”Ÿæˆ""")
                with gr.Column(variant="panel"):
                    # ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®æ‹¡å¼µå­ã‚’å–å¾—
                    supported_extensions = (
                        self.content_extractor.get_supported_extensions()
                    )

                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
                    file_input = gr.File(
                        file_types=supported_extensions,
                        type="filepath",
                        label=f"è§£èª¬å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆ{', '.join(supported_extensions)}ï¼‰",
                    )

                    extracted_text = gr.Textbox(
                        label="è§£èª¬å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆï¼ˆãƒˆãƒ¼ã‚¯ã®å…ƒãƒã‚¿ï¼‰",
                        placeholder="ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ç›´æ¥ã“ã“ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„...",
                        lines=10,
                    )

                with gr.Column(variant="panel"):
                    gr.Markdown("### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š")

                    document_type_radio = gr.Radio(
                        choices=DocumentType.get_all_label_names(),
                        value=self.current_document_type.label_name,
                        label="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—",
                        elem_id="document_type_radio_group",
                    )

                    podcast_mode_radio = gr.Radio(
                        choices=PodcastMode.get_all_label_names(),
                        value=self.current_podcast_mode.label_name,
                        label="ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰",
                        elem_id="podcast_mode_radio_group",
                    )

                    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®š
                    with gr.Accordion(label="ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®š", open=False):
                        with gr.Row():
                            available_characters = self.get_available_characters()
                            character1_dropdown = gr.Dropdown(
                                choices=available_characters,
                                value="å››å›½ã‚ãŸã‚“",
                                label="ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼1ï¼ˆå°‚é–€å®¶å½¹ï¼‰",
                            )
                            character2_dropdown = gr.Dropdown(
                                choices=available_characters,
                                value="ãšã‚“ã ã‚‚ã‚“",
                                label="ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼2ï¼ˆåˆå­¦è€…å½¹ï¼‰",
                            )

                with gr.Column(variant="panel"):
                    # LLM APIè¨­å®šã‚¿ãƒ–
                    llm_tabs = gr.Tabs()
                    with llm_tabs:
                        with gr.TabItem("Google Gemini") as gemini_tab:
                            with gr.Row():
                                with gr.Column(scale=3):
                                    gemini_api_key_input = gr.Textbox(
                                        placeholder="AIza...",
                                        type="password",
                                        label="Google Gemini APIã‚­ãƒ¼",
                                        info="APIã‚­ãƒ¼ã®å–å¾—: https://aistudio.google.com/app/apikey",
                                    )
                                with gr.Column(scale=2):
                                    gemini_model_dropdown = gr.Dropdown(
                                        choices=self.get_gemini_available_models(),
                                        value=self.get_gemini_current_model(),
                                        label="ãƒ¢ãƒ‡ãƒ«",
                                    )
                            with gr.Row():
                                gemini_max_tokens_slider = gr.Slider(
                                    minimum=100,
                                    maximum=65536,
                                    value=self.get_gemini_max_tokens(),
                                    step=100,
                                    label="æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°",
                                )

                        with gr.TabItem("OpenAI") as openai_tab:
                            with gr.Row():
                                with gr.Column(scale=3):
                                    openai_api_key_input = gr.Textbox(
                                        placeholder="sk-...",
                                        type="password",
                                        label="OpenAI APIã‚­ãƒ¼",
                                        info="APIã‚­ãƒ¼ã®å–å¾—: https://platform.openai.com/api-keys",
                                    )
                                with gr.Column(scale=2):
                                    openai_model_dropdown = gr.Dropdown(
                                        choices=self.get_openai_available_models(),
                                        value=self.get_openai_current_model(),
                                        label="ãƒ¢ãƒ‡ãƒ«",
                                    )
                            with gr.Row():
                                openai_max_tokens_slider = gr.Slider(
                                    minimum=100,
                                    maximum=32768,
                                    value=self.get_openai_max_tokens(),
                                    step=100,
                                    label="æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°",
                                )

                    # ãƒˆãƒ¼ã‚¯åŸç¨¿ã‚’ç”Ÿæˆãƒœã‚¿ãƒ³
                    process_btn = gr.Button(
                        "ãƒˆãƒ¼ã‚¯åŸç¨¿ã‚’ç”Ÿæˆ", variant="secondary", interactive=False
                    )
                    podcast_text = gr.Textbox(
                        label="ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯åŸç¨¿",
                        placeholder="ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã—ã¦ãƒˆãƒ¼ã‚¯åŸç¨¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„...",
                        lines=15,
                    )

                    # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨çŠ¶æ³ã®è¡¨ç¤º
                    token_usage_info = gr.HTML(
                        "<div>ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨çŠ¶æ³: ã¾ã ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“</div>", elem_id="token-usage-info"
                    )

            with gr.Column():
                gr.Markdown("## ãƒˆãƒ¼ã‚¯éŸ³å£°ã®ç”Ÿæˆ")
                with gr.Column(variant="panel"):
                    msg = """éŸ³å£°ã¯ä¸‹è¨˜ã®éŸ³æºã‚’ä½¿ç”¨ã—ã¦ç”Ÿæˆã•ã‚Œã¾ã™ã€‚
                    VOICEVOX:å››å›½ã‚ãŸã‚“ã€VOICEVOX:ãšã‚“ã ã‚‚ã‚“ã€VOICEVOX:ä¹å·ãã‚‰ã€VOICEVOX:ä¸­å›½ã†ã•ãã€VOICEVOX:ä¸­éƒ¨ã¤ã‚‹ã
                    éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹ã«ã¯[VOICEVOX éŸ³æºåˆ©ç”¨è¦ç´„](https://zunko.jp/con_ongen_kiyaku.html)ã¸ã®åŒæ„ãŒå¿…è¦ã§ã™ã€‚
                    """
                    # VOICEVOXåˆ©ç”¨è¦ç´„ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’ã“ã“ã«é…ç½®
                    terms_checkbox = gr.Checkbox(
                        label="VOICEVOX éŸ³æºåˆ©ç”¨è¦ç´„ã«åŒæ„ã™ã‚‹",
                        value=False,
                        info=msg,
                    )
                    generate_btn = gr.Button(
                        "éŸ³å£°ã‚’ç”Ÿæˆ", variant="primary", interactive=False
                    )

                    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å†ç”Ÿç”¨ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
                    streaming_audio_output = gr.Audio(
                        type="filepath",
                        format="wav",
                        interactive=False,
                        show_download_button=False,
                        show_label=True,
                        label="ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼",
                        value=None,
                        elem_id="streaming_audio_output",
                        streaming=True,
                    )

                    # æœ€çµ‚çš„ãªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
                    # NOTE: gradioã®ä»•æ§˜ä¸Š, ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ã®Audioã§ã¯æ³¢å½¢ãŒè¡¨ç¤ºã§ããªã„ãŸã‚, ã“ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§æ³¢å½¢ã‚’è¡¨ç¤ºã™ã‚‹
                    audio_output = gr.Audio(
                        type="filepath",
                        format="wav",
                        interactive=False,
                        show_download_button=True,
                        show_label=True,
                        label="å®ŒæˆéŸ³å£°",
                        value=None,
                        elem_id="audio_output",
                        waveform_options=gr.WaveformOptions(
                            show_recording_waveform=True,
                            waveform_color="#3498db",
                            waveform_progress_color="#27ae60",
                        ),
                        min_width=300,
                    )

            # Set up event handlers
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚‰è‡ªå‹•çš„ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆå¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯æ™‚é–“ãŒã‹ã‹ã‚‹ã®ã§ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°ï¼‰
            file_input.change(
                fn=self.extract_file_text,
                inputs=[file_input],
                outputs=[extracted_text],
                concurrency_limit=1,  # åŒæ™‚å®Ÿè¡Œæ•°ã‚’1ã«åˆ¶é™ï¼ˆHugging Face Spaceså¯¾å¿œï¼‰
                concurrency_id="file_queue",  # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ç”¨ã‚­ãƒ¥ãƒ¼ID
            ).then(
                fn=self.update_process_button_state,
                inputs=[extracted_text],
                outputs=[process_btn],
            )

            # OpenAI API key - ãƒ¦ãƒ¼ã‚¶ãŒå…¥åŠ›ã—ãŸã‚‰ã™ãã«ä¿å­˜
            openai_api_key_input.change(
                fn=self.set_openai_api_key,
                inputs=[openai_api_key_input],
                outputs=[],
            ).then(
                fn=self.update_process_button_state,
                inputs=[extracted_text],
                outputs=[process_btn],
            )

            # Gemini API key
            gemini_api_key_input.change(
                fn=self.set_gemini_api_key,
                inputs=[gemini_api_key_input],
                outputs=[],
            ).then(
                fn=self.update_process_button_state,
                inputs=[extracted_text],
                outputs=[process_btn],
            )

            # ã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆæ™‚ã®LLMã‚¿ã‚¤ãƒ—å¤‰æ›´
            gemini_tab.select(
                fn=lambda: self.switch_llm_type("gemini"),
                outputs=[],
            )

            openai_tab.select(
                fn=lambda: self.switch_llm_type("openai"),
                outputs=[],
            )

            # OpenAI Model selection
            openai_model_dropdown.change(
                fn=self.set_openai_model_name,
                inputs=[openai_model_dropdown],
                outputs=[],
            )

            # Gemini Model selection
            gemini_model_dropdown.change(
                fn=self.set_gemini_model_name,
                inputs=[gemini_model_dropdown],
                outputs=[],
            )

            # OpenAI Max tokens selection
            openai_max_tokens_slider.change(
                fn=self.set_openai_max_tokens,
                inputs=[openai_max_tokens_slider],
                outputs=[],
            )

            # Gemini Max tokens selection
            gemini_max_tokens_slider.change(
                fn=self.set_gemini_max_tokens,
                inputs=[gemini_max_tokens_slider],
                outputs=[],
            )

            character1_dropdown.change(
                fn=self.set_character_mapping,
                inputs=[character1_dropdown, character2_dropdown],
                outputs=[],
            )

            character2_dropdown.change(
                fn=self.set_character_mapping,
                inputs=[character1_dropdown, character2_dropdown],
                outputs=[],
            )

            # VOICEVOX Terms checkbox - éŸ³å£°ç”Ÿæˆãƒœã‚¿ãƒ³ã«å¯¾ã—ã¦ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ã‚’æ›´æ–°
            terms_checkbox.change(
                fn=self.update_audio_button_state,
                inputs=[terms_checkbox, podcast_text],
                outputs=[generate_btn],
            )

            # ãƒˆãƒ¼ã‚¯åŸç¨¿ã®ç”Ÿæˆå‡¦ç†ï¼ˆæ™‚é–“ã®ã‹ã‹ã‚‹LLMå‡¦ç†ãªã®ã§ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°ã‚’é©ç”¨ï¼‰
            # 1. ã¾ãšãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–
            process_events = process_btn.click(
                fn=self.disable_process_button,
                inputs=[],
                outputs=[process_btn],
                queue=False,  # å³æ™‚å®Ÿè¡Œ
                api_name="disable_process_button",
            )

            # 2. ãƒˆãƒ¼ã‚¯åŸç¨¿ã®ç”Ÿæˆå‡¦ç†
            process_events.then(
                fn=self.generate_podcast_text,
                inputs=[extracted_text],
                outputs=[podcast_text],
                concurrency_limit=1,  # åŒæ™‚å®Ÿè¡Œæ•°ã‚’1ã«åˆ¶é™ï¼ˆHugging Face Spaceså¯¾å¿œï¼‰
                concurrency_id="llm_queue",  # LLMé–¢é€£ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨ã‚­ãƒ¥ãƒ¼ID
            ).then(
                # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨çŠ¶æ³ã‚’UIã«åæ˜ 
                fn=self.update_token_usage_display,
                outputs=[token_usage_info],
            ).then(
                # ãƒˆãƒ¼ã‚¯åŸç¨¿ç”Ÿæˆå¾Œã«éŸ³å£°ç”Ÿæˆãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã‚’æ›´æ–°
                fn=self.update_audio_button_state,
                inputs=[terms_checkbox, podcast_text],
                outputs=[generate_btn],
            ).then(
                # 3. æœ€å¾Œã«ãƒˆãƒ¼ã‚¯åŸç¨¿ç”Ÿæˆãƒœã‚¿ãƒ³ã‚’å†åº¦æœ‰åŠ¹åŒ–
                fn=self.enable_process_button,
                inputs=[extracted_text],
                outputs=[process_btn],
                queue=False,  # å³æ™‚å®Ÿè¡Œ
                api_name="enable_process_button",
            )

            # éŸ³å£°ç”Ÿæˆãƒœã‚¿ãƒ³ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å†ç”Ÿã¨æœ€çµ‚æ³¢å½¢è¡¨ç¤ºã‚’ä¸¦åˆ—å‡¦ç†ï¼‰

            # ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–ã™ã‚‹ï¼ˆã‚¯ãƒªãƒƒã‚¯æ™‚ï¼‰
            disable_btn_event = generate_btn.click(
                fn=self.disable_generate_button,
                inputs=[],
                outputs=[generate_btn],
                queue=False,  # å³æ™‚å®Ÿè¡Œ
                api_name="disable_generate_button",
            )

            # 0. éŸ³å£°ç”ŸæˆçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å†ç”Ÿã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã‚¯ãƒªã‚¢
            audio_events = disable_btn_event.then(
                fn=self.reset_audio_state_and_components,
                inputs=[],
                outputs=[streaming_audio_output],
                concurrency_id="audio_reset",
                concurrency_limit=1,  # åŒæ™‚å®Ÿè¡Œæ•°ã‚’1ã«åˆ¶é™
                api_name="reset_audio_state",
            )

            # 1. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å†ç”Ÿé–‹å§‹ (éŸ³å£°ãƒ‘ãƒ¼ãƒ„ç”Ÿæˆã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å†ç”Ÿ)
            audio_events.then(
                fn=self.generate_podcast_audio_streaming,
                inputs=[podcast_text],
                outputs=[streaming_audio_output],
                concurrency_limit=1,  # éŸ³å£°ç”Ÿæˆã¯1ã¤ãšã¤å®Ÿè¡Œ
                concurrency_id="audio_queue",  # éŸ³å£°ç”Ÿæˆç”¨ã‚­ãƒ¥ãƒ¼ID
                show_progress=False,  # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºã§ã¯ç‹¬è‡ªã®é€²æ—ãƒãƒ¼ã‚’è¡¨ç¤ºã—ãªã„
                api_name="generate_streaming_audio",  # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            )

            # 2. æ³¢å½¢è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’æ›´æ–° (é€²æ—è¡¨ç¤ºã¨ã¨ã‚‚ã«æœ€çµ‚æ³¢å½¢è¡¨ç¤º)
            # ã“ã¡ã‚‰ã¯ç‹¬ç«‹ã—ãŸã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦å®Ÿè¡Œã—ã€éŸ³å£°ç”Ÿæˆã®é€²æ—ã‚’è¡¨ç¤ºã—ã¦ã‹ã‚‰æœ€çµ‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™
            wave_display_event = generate_btn.click(
                fn=self.wait_for_audio_completion,
                inputs=[podcast_text],
                outputs=[audio_output],
                concurrency_limit=1,  # åŒæ™‚å®Ÿè¡Œæ•°ã‚’1ã«åˆ¶é™
                concurrency_id="progress_queue",  # é€²æ—è¡¨ç¤ºç”¨ã‚­ãƒ¥ãƒ¼ID
                show_progress=True,  # é€²æ—ãƒãƒ¼ã‚’è¡¨ç¤ºï¼ˆé–¢æ•°å†…ã§æ›´æ–°ï¼‰
                api_name="update_progress_display",  # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            )

            # 3. å‡¦ç†å®Œäº†å¾Œã«ãƒœã‚¿ãƒ³ã‚’å†åº¦æœ‰åŠ¹åŒ–
            wave_display_event.then(
                fn=self.enable_generate_button,
                inputs=[podcast_text],
                outputs=[generate_btn],
                queue=False,  # å³æ™‚å®Ÿè¡Œ
                api_name="enable_generate_button",
            )

            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—é¸æŠã®ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
            document_type_radio.change(
                fn=self.set_document_type,
                inputs=[document_type_radio],
                outputs=[],
            )

            # ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰é¸æŠã®ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
            podcast_mode_radio.change(
                fn=self.set_podcast_mode,
                inputs=[podcast_mode_radio],
                outputs=[],
            )

            # podcast_textã®å¤‰æ›´æ™‚ã«ã‚‚éŸ³å£°ç”Ÿæˆãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã‚’æ›´æ–°
            podcast_text.change(
                fn=self.update_audio_button_state,
                inputs=[terms_checkbox, podcast_text],
                outputs=[generate_btn],
            )

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ–ãƒ©ã‚¦ã‚¶ã‚¿ãƒ–ã‚’é–‰ã˜ã‚‹ã‹ãƒªãƒ­ãƒ¼ãƒ‰ã—ãŸã¨ãã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            app.unload(
                fn=self.cleanup_session,
            )

        return app

    def get_openai_available_models(self) -> List[str]:
        """
        åˆ©ç”¨å¯èƒ½ãªOpenAIãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚

        Returns:
            List[str]: åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«åã®ãƒªã‚¹ãƒˆ
        """
        return self.text_processor.openai_model.get_available_models()

    def get_openai_current_model(self) -> str:
        """
        ç¾åœ¨è¨­å®šã•ã‚Œã¦ã„ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—ã—ã¾ã™ã€‚

        Returns:
            str: ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«å
        """
        return self.text_processor.openai_model.model_name

    def get_gemini_available_models(self) -> List[str]:
        """
        åˆ©ç”¨å¯èƒ½ãªGeminiãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚

        Returns:
            List[str]: åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«åã®ãƒªã‚¹ãƒˆ
        """
        return self.text_processor.gemini_model.get_available_models()

    def get_gemini_current_model(self) -> str:
        """
        ç¾åœ¨è¨­å®šã•ã‚Œã¦ã„ã‚‹Geminiãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—ã—ã¾ã™ã€‚

        Returns:
            str: ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«å
        """
        return self.text_processor.gemini_model.model_name

    def set_openai_model_name(self, model_name: str) -> None:
        """
        OpenAIãƒ¢ãƒ‡ãƒ«åã‚’è¨­å®šã—ã¾ã™ã€‚

        Args:
            model_name (str): ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        """
        success = self.text_processor.openai_model.set_model_name(model_name)
        logger.debug(f"OpenAI model set to {model_name}: {success}")

    def set_gemini_model_name(self, model_name: str) -> None:
        """
        Geminiãƒ¢ãƒ‡ãƒ«åã‚’è¨­å®šã—ã¾ã™ã€‚

        Args:
            model_name (str): ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        """
        success = self.text_processor.gemini_model.set_model_name(model_name)
        logger.debug(f"Gemini model set to {model_name}: {success}")

    def get_openai_max_tokens(self) -> int:
        """
        ç¾åœ¨è¨­å®šã•ã‚Œã¦ã„ã‚‹OpenAIã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å–å¾—ã—ã¾ã™ã€‚

        Returns:
            int: ç¾åœ¨ã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        """
        return self.text_processor.openai_model.get_max_tokens()

    def get_gemini_max_tokens(self) -> int:
        """
        ç¾åœ¨è¨­å®šã•ã‚Œã¦ã„ã‚‹Geminiã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å–å¾—ã—ã¾ã™ã€‚

        Returns:
            int: ç¾åœ¨ã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        """
        return self.text_processor.gemini_model.get_max_tokens()

    def set_openai_max_tokens(self, max_tokens: int) -> None:
        """
        OpenAIã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚

        Args:
            max_tokens (int): è¨­å®šã™ã‚‹æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        """
        success = self.text_processor.openai_model.set_max_tokens(max_tokens)
        logger.debug(f"OpenAI max tokens set to {max_tokens}: {success}")

    def set_gemini_max_tokens(self, max_tokens: int) -> None:
        """
        Geminiã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚

        Args:
            max_tokens (int): è¨­å®šã™ã‚‹æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        """
        success = self.text_processor.gemini_model.set_max_tokens(max_tokens)
        logger.debug(f"Gemini max tokens set to {max_tokens}: {success}")

    def get_available_characters(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚

        Returns:
            List[str]: åˆ©ç”¨å¯èƒ½ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã®ãƒªã‚¹ãƒˆ
        """
        return DISPLAY_NAMES

    def set_character_mapping(self, character1: str, character2: str) -> None:
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’è¨­å®šã—ã¾ã™ã€‚

        Args:
            character1 (str): Character1ã«å‰²ã‚Šå½“ã¦ã‚‹ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å
            character2 (str): Character2ã«å‰²ã‚Šå½“ã¦ã‚‹ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å
        """
        success = self.text_processor.set_character_mapping(character1, character2)
        logger.debug(f"Character mapping set: {character1}, {character2}: {success}")

    def update_process_button_state(self, extracted_text: str) -> Dict[str, Any]:
        """
        æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã¨APIã‚­ãƒ¼ã®çŠ¶æ…‹ã«åŸºã¥ã„ã¦"ãƒˆãƒ¼ã‚¯åŸç¨¿ã‚’ç”Ÿæˆ"ãƒœã‚¿ãƒ³ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚

        Args:
            extracted_text (str): æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            Dict[str, Any]: gr.update()ã®çµæœ
        """
        # ãƒ†ã‚­ã‚¹ãƒˆãŒæœ‰åŠ¹ã‹ã¤APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ãƒœã‚¿ãƒ³ã‚’æœ‰åŠ¹åŒ–
        has_text = (
            extracted_text
            and extracted_text.strip() != ""
            and extracted_text
            not in ["Please upload a file.", "Failed to process the file."]
        )
        has_api_key = False

        if self.current_llm_type == "openai":
            has_api_key = bool(self.text_processor.openai_model.api_key)
        elif self.current_llm_type == "gemini":
            has_api_key = bool(self.text_processor.gemini_model.api_key)

        is_enabled = has_text and has_api_key

        # gr.update()ã‚’ä½¿ç”¨ã—ã¦ã€Gradioã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’æ›´æ–°ã™ã‚‹
        # Dict[str, Any]å‹ã«ã‚­ãƒ£ã‚¹ãƒˆã—ã¦å‹ãƒã‚§ãƒƒã‚«ãƒ¼ã‚’æº€è¶³ã•ã›ã‚‹
        result = gr.update(
            interactive=is_enabled, variant="primary" if is_enabled else "secondary"
        )
        return result  # type: ignore

    def set_podcast_mode(self, mode: str) -> None:
        """
        ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ã‚’è¨­å®šã—ã¾ã™ã€‚

        Args:
            mode (str): ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®ãƒ©ãƒ™ãƒ«å
        """
        try:
            # ãƒ©ãƒ™ãƒ«åã‹ã‚‰PodcastModeã‚’å–å¾—
            podcast_mode = PodcastMode.from_label_name(mode)

            # TextProcessorã‚’ä½¿ã£ã¦PodcastModeã®Enumã‚’è¨­å®š
            success = self.text_processor.set_podcast_mode(podcast_mode.value)

            logger.debug(f"Podcast mode set to {mode}: {success}")

        except ValueError as e:
            logger.error(f"Error setting podcast mode: {str(e)}")

    def get_podcast_modes(self):
        """
        åˆ©ç”¨å¯èƒ½ãªãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚

        Returns:
            list: åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ¼ãƒ‰ã®ãƒ©ãƒ™ãƒ«åãƒªã‚¹ãƒˆ
        """
        return PodcastMode.get_all_label_names()

    def update_token_usage_display(self) -> str:
        """
        ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨çŠ¶æ³ã‚’è¡¨ç¤ºç”¨ã®HTMLã¨ã—ã¦è¿”ã—ã¾ã™ã€‚

        Returns:
            str: ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨çŠ¶æ³ã®HTML
        """
        token_usage = self.text_processor.get_token_usage()
        if not token_usage:
            return "<div>ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨çŠ¶æ³: ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“</div>"

        prompt_tokens = token_usage.get("prompt_tokens", math.nan)
        completion_tokens = token_usage.get("completion_tokens", math.nan)
        total_tokens = token_usage.get("total_tokens", math.nan)

        # APIåã‚’å–å¾—
        api_name = (
            "OpenAI API"
            if self.text_processor.current_api_type == "openai"
            else "Google Gemini API"
        )

        html = f"""
        <div style="padding: 10px; border: 1px solid #ddd; border-radius: 5px; margin-top: 10px;">
            <h3 style="margin-top: 0; margin-bottom: 8px;">{api_name} Token Usage</h3>
            <div style="display: flex; justify-content: space-between;">
                <div><strong>Input Tokens:</strong> {prompt_tokens}</div>
                <div><strong>Output Tokens:</strong> {completion_tokens}</div>
                <div><strong>Total Tokens:</strong> {total_tokens}</div>
            </div>
        </div>
        """
        return html

    def update_audio_button_state(
        self, checked: bool, podcast_text: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        VOICEVOXåˆ©ç”¨è¦ç´„ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®çŠ¶æ…‹ã¨ãƒˆãƒ¼ã‚¯åŸç¨¿ã®æœ‰ç„¡ã«åŸºã¥ã„ã¦éŸ³å£°ç”Ÿæˆãƒœã‚¿ãƒ³ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚

        Args:
            checked (bool): ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®çŠ¶æ…‹
            podcast_text (Optional[str], optional): ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯åŸç¨¿

        Returns:
            Dict[str, Any]: gr.update()ã®çµæœ
        """
        has_text = podcast_text and podcast_text.strip() != ""
        is_enabled = checked and has_text

        message = ""
        if not checked:
            message = "ï¼ˆVOICEVOXåˆ©ç”¨è¦ç´„ã«åŒæ„ãŒå¿…è¦ã§ã™ï¼‰"
        elif not has_text:
            message = "ï¼ˆãƒˆãƒ¼ã‚¯åŸç¨¿ãŒå¿…è¦ã§ã™ï¼‰"

        # gr.update()ã‚’ä½¿ç”¨ã—ã¦ã€æ—¢å­˜ã®ãƒœã‚¿ãƒ³ã‚’æ›´æ–°
        result: Dict[str, Any] = gr.update(
            value=f"éŸ³å£°ã‚’ç”Ÿæˆ{message}",
            interactive=is_enabled,
            variant="primary" if is_enabled else "secondary",
        )
        return result

    def set_document_type(self, doc_type: str) -> None:
        """
        ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã‚’è¨­å®šã—ã¾ã™ã€‚

        Args:
            doc_type (str): ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®ãƒ©ãƒ™ãƒ«å
        """
        try:
            # ãƒ©ãƒ™ãƒ«åã‹ã‚‰DocumentTypeã‚’å–å¾—
            document_type = DocumentType.from_label_name(doc_type)

            # TextProcessorã‚’ä½¿ã£ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã‚’è¨­å®š
            success = self.text_processor.set_document_type(document_type)

            logger.debug(f"Document type set to {doc_type}: {success}")

        except ValueError as e:
            logger.error(f"Error setting document type: {str(e)}")

    def wait_for_audio_completion(self, text: str, progress=gr.Progress()):
        """
        ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã®é€²æ—ã‚’è¡¨ç¤ºã—ã€æœ€çµ‚çš„ãªçµåˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™
        æ³¢å½¢è¡¨ç¤ºç”¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®æ›´æ–°ã«ä½¿ç”¨ã™ã‚‹
        éŸ³å£°ç”ŸæˆãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿã—ã€æœ€çµ‚çš„ãªçµåˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™

        Args:
            text (str): Generated podcast text (ä½¿ç”¨ã—ãªã„)
            progress (gr.Progress): Gradio Progress object for updating progress

        Returns:
            Optional[str]: æœ€çµ‚çµåˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆã™ã¹ã¦ã®ä¼šè©±ã‚’å«ã‚€ï¼‰
        """
        if not text or not self.audio_generator.core_initialized:
            logger.warning(
                "Cannot display progress: Text is empty or VOICEVOX is not available"
            )
            progress(1.0, desc="âš ï¸ éŸ³å£°ç”Ÿæˆã§ãã¾ã›ã‚“")
            return None

        # é€²æ—è¡¨ç¤ºã®åˆæœŸåŒ–
        progress(0, desc="éŸ³å£°ç”Ÿæˆæº–å‚™ä¸­...")

        # éŸ³å£°ç”Ÿæˆã®å®Œäº†ã‚’å¾…ã¡ãªãŒã‚‰é€²æ—è¡¨ç¤ºã‚’è¡Œã†
        last_progress = -math.inf
        while True:
            current_value = self.audio_generator.audio_generation_progress

            # ç”Ÿæˆå®Œäº†ã—ãŸã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã‚’è©¦ã¿ã‚‹
            if current_value >= 1.0:
                if self.audio_generator.final_audio_path is None:
                    progress(1.0, desc="âœ… éŸ³å£°ç”Ÿæˆå®Œäº†! éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ä¸­...")
                else:
                    abs_path = str(
                        Path(self.audio_generator.final_audio_path).absolute()
                    )
                    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã‘ã‚Œã°ã‚¨ãƒ©ãƒ¼
                    if not os.path.exists(abs_path):
                        logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {abs_path}")
                        progress(1.0, desc="âš ï¸ éŸ³å£°ç”Ÿæˆã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                        return None
                    filesize = os.path.getsize(abs_path)
                    logger.info(f"æœ€çµ‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã—ã¾ã™: {abs_path} (ã‚µã‚¤ã‚º: {filesize} bytes)")
                    progress(1.0, desc="âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—å®Œäº†!")
                    return abs_path

            # 1%ä»¥ä¸Šå¤‰åŒ–ãŒã‚ã‚Œã°æ›´æ–°
            if abs(current_value - last_progress) > 0.01:
                last_progress = current_value
                progress_percent = int(current_value * 100)

                # é€²æ—ã«å¿œã˜ãŸçµµæ–‡å­—è¡¨ç¤º
                if progress_percent < 25:
                    emoji = "ğŸ¤"
                elif progress_percent < 50:
                    emoji = "ğŸµ"
                elif progress_percent < 75:
                    emoji = "ğŸ¶"
                else:
                    emoji = "ğŸ”Š"

                # é€²æ—ã‚’æ›´æ–°
                progress(current_value, desc=f"{emoji} éŸ³å£°ç”Ÿæˆä¸­... {progress_percent}%")

            # ä¸€å®šæ™‚é–“å¾…æ©Ÿã—ã¦ã‹ã‚‰å†ãƒã‚§ãƒƒã‚¯
            time.sleep(0.5)

    def reset_audio_state_and_components(self):
        """
        éŸ³å£°ç”ŸæˆçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã€UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚‚ã‚¯ãƒªã‚¢ã™ã‚‹
        æ–°ã—ã„éŸ³å£°ç”Ÿæˆã‚’é–‹å§‹ã™ã‚‹å‰ã«å‘¼ã³å‡ºã™

        Returns:
            None: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å†ç”Ÿã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãŸã‚ã«Noneã‚’è¿”ã™
        """
        # éŸ³å£°ç”ŸæˆçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        self.audio_generator.reset_audio_generation_state()

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ - gradio UIã®æ›´æ–°ã®ãŸã‚Noneã‚’è¿”ã™
        logger.debug("Audio components and generation state reset")
        return None

    def cleanup_session(self):
        """
        ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒçµ‚äº†ã—ãŸæ™‚ã«å‘¼ã³å‡ºã•ã‚Œã‚‹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–¢æ•°ã€‚
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ–ãƒ©ã‚¦ã‚¶ã‚¿ãƒ–ã‚’é–‰ã˜ãŸã‚Šæ›´æ–°ã—ãŸã‚Šã—ãŸæ™‚ã«å®Ÿè¡Œã•ã‚Œã‚‹ã€‚

        ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒ†ãƒ³ãƒãƒ©ãƒªãƒ•ã‚¡ã‚¤ãƒ«ã¨å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹ã€‚

        Returns:
            None
        """
        logger.info(
            f"Session {self.session_manager.get_session_id()} ended, cleaning up..."
        )
        success = self.session_manager.cleanup_session_data()
        if success:
            logger.info("Session cleanup completed successfully")
        else:
            logger.warning("Session cleanup encountered issues")


# Create and launch application instance
def main():
    """Application entry point.

    Creates an instance of PaperPodcastApp and launches the application.
    """
    app_instance = PaperPodcastApp()
    app = app_instance.ui()

    # Get port from environment variable or use default
    port = int(os.environ.get("PORT", DEFAULT_PORT))

    # E2E test mode options
    inbrowser = not E2E_TEST_MODE  # Don't open browser in test mode

    # ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°ã¯launchã®å‰ã«queueãƒ¡ã‚½ãƒƒãƒ‰ã§è¨­å®šæ¸ˆã¿
    app.launch(
        server_name="0.0.0.0",
        server_port=port,
        share=False,
        favicon_path="assets/favicon.ico",
        inbrowser=inbrowser,
        quiet=False,  # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º
    )


if __name__ == "__main__":
    main()
